{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priyanka/.cache/pypoetry/virtualenvs/vfm-nn-DOmiObSy-py3.10/lib/python3.10/site-packages/pytorch_forecasting/models/base_model.py:30: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, QuantileLoss\n",
    "from pytorch_forecasting.data.encoders import GroupNormalizer\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priyanka/.cache/pypoetry/virtualenvs/vfm-nn-DOmiObSy-py3.10/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "  rank_zero_warn(\n",
      "/home/priyanka/.cache/pypoetry/virtualenvs/vfm-nn-DOmiObSy-py3.10/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'__special_save__'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mTemporalFusionTransformer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_from_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcheckpoints/best_model.ckpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/vfm-nn-DOmiObSy-py3.10/lib/python3.10/site-packages/lightning/pytorch/core/module.py:1520\u001B[0m, in \u001B[0;36mLightningModule.load_from_checkpoint\u001B[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001B[0m\n\u001B[1;32m   1440\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m   1441\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_from_checkpoint\u001B[39m(\n\u001B[1;32m   1442\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1447\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m   1448\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Self:\n\u001B[1;32m   1449\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1450\u001B[0m \u001B[38;5;124;03m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001B[39;00m\n\u001B[1;32m   1451\u001B[0m \u001B[38;5;124;03m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1518\u001B[0m \u001B[38;5;124;03m        y_hat = pretrained_model(x)\u001B[39;00m\n\u001B[1;32m   1519\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1520\u001B[0m     loaded \u001B[38;5;241m=\u001B[39m \u001B[43m_load_from_checkpoint\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1521\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheckpoint_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1523\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1524\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhparams_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1525\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1526\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1527\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1528\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(Self, loaded)\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/vfm-nn-DOmiObSy-py3.10/lib/python3.10/site-packages/lightning/pytorch/core/saving.py:90\u001B[0m, in \u001B[0;36m_load_from_checkpoint\u001B[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001B[0m\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_state(\u001B[38;5;28mcls\u001B[39m, checkpoint, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mcls\u001B[39m, pl\u001B[38;5;241m.\u001B[39mLightningModule):\n\u001B[0;32m---> 90\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43m_load_state\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     91\u001B[0m     state_dict \u001B[38;5;241m=\u001B[39m checkpoint[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstate_dict\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     92\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m state_dict:\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/vfm-nn-DOmiObSy-py3.10/lib/python3.10/site-packages/lightning/pytorch/core/saving.py:147\u001B[0m, in \u001B[0;36m_load_state\u001B[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001B[0m\n\u001B[1;32m    143\u001B[0m obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_cls_kwargs)\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj, pl\u001B[38;5;241m.\u001B[39mLightningModule):\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;66;03m# give model a chance to load something\u001B[39;00m\n\u001B[0;32m--> 147\u001B[0m     \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_load_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj, pl\u001B[38;5;241m.\u001B[39mLightningDataModule):\n\u001B[1;32m    150\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m \u001B[38;5;129;01min\u001B[39;00m checkpoint:\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/vfm-nn-DOmiObSy-py3.10/lib/python3.10/site-packages/pytorch_forecasting/models/base_model.py:1276\u001B[0m, in \u001B[0;36mBaseModel.on_load_checkpoint\u001B[0;34m(self, checkpoint)\u001B[0m\n\u001B[1;32m   1274\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset_parameters \u001B[38;5;241m=\u001B[39m checkpoint\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset_parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m   1275\u001B[0m \u001B[38;5;66;03m# load specials\u001B[39;00m\n\u001B[0;32m-> 1276\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m \u001B[43mcheckpoint\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCHECKPOINT_HYPER_PARAMS_SPECIAL_KEY\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m   1277\u001B[0m     \u001B[38;5;28msetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, k, v)\n",
      "\u001B[0;31mKeyError\u001B[0m: '__special_save__'"
     ]
    }
   ],
   "source": [
    "model = TemporalFusionTransformer.load_from_checkpoint(checkpoint_path=\"checkpoints/best_model.ckpt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
